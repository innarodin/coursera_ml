{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading data\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "features_test = pd.read_csv('features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Deleting features we don't have in test dataset\n",
    "features_answr_data = features[['duration', 'radiant_win', 'tower_status_radiant', 'tower_status_dire', 'barracks_status_radiant', 'barracks_status_dire']]\n",
    "y = features_answr_data['radiant_win']\n",
    "del features['duration'] \n",
    "del features['radiant_win']\n",
    "del features['tower_status_radiant'] \n",
    "del features['tower_status_dire'] \n",
    "del features['barracks_status_radiant'] \n",
    "del features['barracks_status_dire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Searching for features with Nun meanings and filling with 0\n",
    "cnt = features.count()\n",
    "features = features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 10\n",
      "Precision: 0.6648506879750012\n",
      "Time elapsed: 0:00:29.145862 \n",
      "\n",
      "Number of trees: 20\n",
      "Precision: 0.6824618768044435\n",
      "Time elapsed: 0:00:52.375024 \n",
      "\n",
      "Number of trees: 30\n",
      "Precision: 0.6900064710388155\n",
      "Time elapsed: 0:01:14.606087 \n",
      "\n",
      "Number of trees: 40\n",
      "Precision: 0.6940387245121103\n",
      "Time elapsed: 0:01:35.284865 \n",
      "\n",
      "Number of trees: 50\n",
      "Precision: 0.6974943609466162\n",
      "Time elapsed: 0:01:58.886339 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Gradient Boosting\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "clf = KFold(n_splits = 5, shuffle = True, random_state = 42)  ##Partition generator for cross-validation\n",
    "for k in [10, 20, 30, 40, 50]:\n",
    "    start_time = datetime.datetime.now()  ##Time-counter\n",
    "    time.sleep(3)\n",
    "    gbc = GradientBoostingClassifier(n_estimators = k, random_state = 42) \n",
    "    cvs = cross_val_score(estimator = gbc, X = features, y = y, cv = clf, scoring='roc_auc')  \n",
    "    answ = cvs.mean()\n",
    "    print ('Number of trees:', k)\n",
    "    print ('Precision:', answ)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.54436416  1.54068827 -1.24422828 ... -0.55115386  1.84600409\n",
      "  -1.12149424]\n",
      " [-2.54045236 -0.92779756 -0.29225805 ...  0.67817009  0.43778816\n",
      "   0.04394713]\n",
      " [-2.53923104  1.54068827 -0.5686365  ...  0.67817009  0.43778816\n",
      "   0.49028637]\n",
      " ...\n",
      " [ 1.09874571 -0.57515673  1.42743012 ...  0.67817009  0.43778816\n",
      "  -0.20401912]\n",
      " [ 1.09895204 -0.57515673  1.48884755 ...  0.67817009  0.43778816\n",
      "  -0.87352799]\n",
      " [ 1.1026479   1.54068827 -0.04658831 ... -0.55115386 -0.97042777\n",
      "  -0.79913812]]\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "##Preprocessing\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "X_train = scaler.transform(features)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001\n",
      "Precision: 0.7163635378209221\n",
      "Time elapsed: 0:03:09.906313 \n",
      "\n",
      "C: 0.01\n",
      "Precision: 0.7165502697259141\n",
      "Time elapsed: 0:00:15.957636 \n",
      "\n",
      "C: 0.1\n",
      "Precision: 0.7165271486657933\n",
      "Time elapsed: 0:00:17.508568 \n",
      "\n",
      "C: 1\n",
      "Precision: 0.7165226003626438\n",
      "Time elapsed: 0:00:17.524102 \n",
      "\n",
      "C: 10\n",
      "Precision: 0.7165222888959446\n",
      "Time elapsed: 0:00:16.799537 \n",
      "\n",
      "C: 100\n",
      "Precision: 0.7165222952575674\n",
      "Time elapsed: 0:00:16.703701 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:  ##Trying different values of parametr C to find optimal \n",
    "    start_time = datetime.datetime.now()  ##Time-counter\n",
    "    time.sleep(3)\n",
    "    lg = LogisticRegression(penalty = 'l2', random_state = 42, C = C)\n",
    "    cvs = cross_val_score(estimator = lg, X = X_train, y = y, cv = clf, scoring='roc_auc')  \n",
    "    answ = cvs.mean()\n",
    "    print ('C:', C)\n",
    "    print ('Precision:', answ)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time, '\\n')\n",
    "    \n",
    "##Conclusion: we will use C = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Deleting categorical features from dataset\n",
    "y_categorical = features[['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "columns = ['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "features.drop(columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scaling for new set of featuresscaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "X_train_new = scaler.transform(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001\n",
      "Precision: 0.7163757999081172\n",
      "Time elapsed: 0:00:11.416046 \n",
      "\n",
      "C: 0.01\n",
      "Precision: 0.7165593885630225\n",
      "Time elapsed: 0:00:13.945163 \n",
      "\n",
      "C: 0.1\n",
      "Precision: 0.7165342403465319\n",
      "Time elapsed: 0:00:15.469703 \n",
      "\n",
      "C: 1\n",
      "Precision: 0.7165303634514961\n",
      "Time elapsed: 0:00:18.624751 \n",
      "\n",
      "C: 10\n",
      "Precision: 0.7165299715025929\n",
      "Time elapsed: 0:00:15.159210 \n",
      "\n",
      "C: 100\n",
      "Precision: 0.7165298910060073\n",
      "Time elapsed: 0:00:15.876479 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression without categorical features\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:  ##Trying different values of parametr C to find optimal \n",
    "    start_time = datetime.datetime.now()  ##Time-counter\n",
    "    time.sleep(3)\n",
    "    lg = LogisticRegression(penalty = 'l2', random_state = 42, C = C)\n",
    "    cvs = cross_val_score(estimator = lg, X = X_train_new, y = y, cv = clf, scoring='roc_auc')  \n",
    "    answ = cvs.mean()\n",
    "    print ('C:', C)\n",
    "    print ('Precision:', answ)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Counting number of different heroes\n",
    "hero_count = y_categorical['r1_hero'] + y_categorical['r2_hero'] + y_categorical['r3_hero']\n",
    "+ y_categorical['r4_hero'] + y_categorical['r5_hero'] + y_categorical['d1_hero']\n",
    "+ y_categorical['d2_hero'] + y_categorical['d3_hero'] + y_categorical['d4_hero'] + y_categorical['d5_hero'] ##all heroes\n",
    "hero_count = hero_count.unique()\n",
    "hero_count.__len__()\n",
    "\n",
    "##numv=ber of heroes = 317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ana/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ana/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_pick = np.zeros((y_categorical.shape[0], 317)) ## 317 - number of heroes\n",
    "for i, match_id in enumerate(y_categorical.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, y_categorical.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, y_categorical.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001\n",
      "Precision: 0.7463341511009906\n",
      "Time elapsed: 0:00:14.489664 \n",
      "\n",
      "C: 0.01\n",
      "Precision: 0.7517377305756991\n",
      "Time elapsed: 0:00:22.072357 \n",
      "\n",
      "C: 0.1\n",
      "Precision: 0.751947432864572\n",
      "Time elapsed: 0:00:32.974364 \n",
      "\n",
      "C: 1\n",
      "Precision: 0.7519273152918454\n",
      "Time elapsed: 0:00:33.147550 \n",
      "\n",
      "C: 10\n",
      "Precision: 0.7519250751874296\n",
      "Time elapsed: 0:00:31.108165 \n",
      "\n",
      "C: 100\n",
      "Precision: 0.7519248717899478\n",
      "Time elapsed: 0:00:34.551234 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.concatenate((X_train_new, X_pick), axis=1)\n",
    "##Logistic regression with categorical features coded as bag of features\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:  ##Trying different values of parametr C to find optimal \n",
    "    start_time = datetime.datetime.now()  ##Time-counter\n",
    "    time.sleep(3)\n",
    "    lg = LogisticRegression(penalty = 'l2', random_state = 42, C = C)\n",
    "    cvs = cross_val_score(estimator = lg, X = data, y = y, cv = clf, scoring='roc_auc')  \n",
    "    answ = cvs.mean()\n",
    "    print ('C:', C)\n",
    "    print ('Precision:', answ)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Predicting a winning team for test dataset\n",
    "##Training the model\n",
    "lg = LogisticRegression(penalty = 'l2', random_state = 42, C = 0.1)\n",
    "lg.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ana/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/ana/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "##Preprocessing test dataset\n",
    "features_test = features_test.fillna(0)\n",
    "\n",
    "y_categorical_test = features_test[['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "columns = ['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "features_test.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "X_pick_test = np.zeros((y_categorical_test.shape[0], 317)) ## 317 - number of heroes\n",
    "for i, match_id in enumerate(y_categorical_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, y_categorical_test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, y_categorical_test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_test)\n",
    "X_test = scaler.transform(features_test)\n",
    "data_test = np.concatenate((X_test, X_pick_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51587803, 0.66356237, 0.31798575, ..., 0.22524244, 0.35760494,\n",
       "       0.52572676])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lg.predict_proba(data_test)[:, 1]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005789361732874468"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942010945149464"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
