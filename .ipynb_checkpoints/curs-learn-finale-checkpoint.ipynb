{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time =>  77677\n",
      "first_blood_team =>  77677\n",
      "first_blood_player1 =>  77677\n",
      "first_blood_player2 =>  53243\n",
      "radiant_bottle_time =>  81539\n",
      "radiant_courier_time =>  96538\n",
      "radiant_flying_courier_time =>  69751\n",
      "radiant_first_ward_time =>  95394\n",
      "dire_bottle_time =>  81087\n",
      "dire_courier_time =>  96554\n",
      "dire_flying_courier_time =>  71132\n",
      "dire_first_ward_time =>  95404\n",
      "\n",
      "begin GradientBoostingClassifier ...\n",
      "10  ->  0.664742959026921 , time elapsed: 0:00:15.541192\n"
     ]
    }
   ],
   "source": [
    "# features | features_test\n",
    "import pandas \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,r2_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "\n",
    "# Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. \n",
    "features = pandas.read_csv('./data/features.csv', index_col='match_id')\n",
    "features_test = pandas.read_csv('./data/features_test.csv', nrows=1, index_col='match_id')\n",
    "\n",
    "#    Какой столбец содержит целевую переменную? Запишите его название.\n",
    "Y = features['radiant_win']\n",
    "\n",
    "# Оставляем данные из выборки test\n",
    "columns = features_test.columns.tolist() \n",
    "X = features[columns]\n",
    "      \n",
    "#    Проверьте выборку на наличие пропусков с помощью функции count(),\n",
    "#    которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? \n",
    "\n",
    "total = len(X) \n",
    "values = {}\n",
    "for column in columns:\n",
    "    if(X[column].count() < total): \n",
    "        print column, '=> ', X[column].count()\n",
    "        values[column] = X[column].mean()\n",
    "        \n",
    "# заменяем пропущеное значение на среднее   \n",
    "# X = X.fillna(0) #\n",
    "X = X.fillna(value=values)        \n",
    "        \n",
    "# first_blood_time =>  77677 - игровое время первой крови - первая кровь может не пролится за первые 5 мин\n",
    "# first_blood_team =>  77677 - команда, совершившая первую кровь (0 — Radiant, 1 — Dire) - первая кровь может не пролится за первые 5 мин\n",
    "# first_blood_player1 =>  77677 - игрок, причастный к событию  - первая кровь может не пролится за первые 5 мин\n",
    "# first_blood_player2 =>  53243 - второй игрок, причастный к событию - первая кровь может не пролится за первые 5 мин, при этом вероятность еще меньше, т.к. второй игрок не всегда будет фигурировать даже в случившемся событии\n",
    "\n",
    "# radiant_bottle_time =>  81539 - время первого приобретения командой предмета \"bottle\" - не во всех играх происходит это событие\n",
    "# radiant_courier_time =>  96538 -  время приобретения предмета \"courier\"  - не во всех играх происходит это событие\n",
    "# radiant_flying_courier_time =>  69751 - время приобретения предмета \"flying_courier\" - не во всех играх происходит это событие \n",
    "# radiant_first_ward_time =>  95394 - время установки командой первого \"наблюдателя\" - не во всех играх происходит это событие\n",
    "\n",
    "# dire_bottle_time =>  81087\n",
    "# dire_courier_time =>  96554\n",
    "# dire_flying_courier_time =>  71132\n",
    "# dire_first_ward_time =>  95404\n",
    "        \n",
    "#  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#   Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг \n",
    "#   над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации \n",
    "#   по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице \n",
    "#   отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. \n",
    "#   Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, \n",
    "#   попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества \n",
    "#   деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях \n",
    "#   параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=241)\n",
    "roc_auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "print ''\n",
    "print 'begin GradientBoostingClassifier ...'\n",
    "for n in [10]: #[10, 20, 30, 40, 50, 100, 200]:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, random_state=241)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(clf, X_test, y_test, scoring='roc_auc', cv=cv)\n",
    "    print n, ' -> ', scores.mean(),  ', time elapsed:', datetime.datetime.now() - start_time\n",
    "\n",
    "# Вывод обучения\n",
    "# 10  ->  0.664742959026921 , time elapsed: 0:00:16.483141\n",
    "# 20  ->  0.6827726672264218 , time elapsed: 0:00:27.931048\n",
    "# 30  ->  0.6888565208395903 , time elapsed: 0:00:40.445222\n",
    "# 40  ->  0.6932318263791817 , time elapsed: 0:00:54.498139\n",
    "# 50  ->  0.6959346637422967 , time elapsed: 0:01:07.349483\n",
    "# 100  ->  0.7046407181978287 , time elapsed: 0:02:18.671581\n",
    "# 200  ->  0.7096535702483857 , time elapsed: 0:04:35.863579\n",
    "# Из данных можно сделать вывод - скорость обучения (настройки классификатора) ростет линейно от кол-ва деревьев\n",
    "# Оптимальное качество достигается на n_estimators = 30 ~ 0.63, далее хотя качество и продолжает рости, но происходит сильное затухание\n",
    "# И качество существенно не ростет даже при картном увеличении (n_estimators=200)\n",
    "\n",
    "\n",
    "# В отчете по данному этапу вы должны ответить на следующие вопросы:\n",
    "# 1. Какие признаки имеют пропуски среди своих значений? \n",
    "# Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?\n",
    "## Не все события происходят в каждой игре (см. выше.)\n",
    "# 2. Как называется столбец, содержащий целевую переменную?\n",
    "## radiant_win\n",
    "# 3. Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени можно найти ниже по тексту. Какое качество при этом получилось? Напомним, что в данном задании мы используем метрику качества AUC-ROC.\n",
    "## 30  ->  0.6888565208395903 , time elapsed: 0:00:40.445222\n",
    "# 4. Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?\n",
    "## смысла нет, качество изменится не сильно, но время займет много"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin StandardScaler LogisticRegression ..., shape:  (65144, 102)\n",
      "0.0001  ->  0.7044488575866314 , time elapsed: 0:00:02.238369\n",
      "0.001  ->  0.7153558580738213 , time elapsed: 0:00:03.634944\n",
      "0.01  ->  0.716121852574402 , time elapsed: 0:00:05.910902\n",
      "0.1  ->  0.7159255905069706 , time elapsed: 0:00:07.018061\n",
      "1  ->  0.7158944792086537 , time elapsed: 0:00:07.112317\n",
      "10.0  ->  0.7158899279505536 , time elapsed: 0:00:07.051983\n",
      "100.0  ->  0.7158893832069998 , time elapsed: 0:00:07.206414\n",
      "1000.0  ->  0.7158893637590881 , time elapsed: 0:00:07.374739\n",
      "10000.0  ->  0.7158893248443823 , time elapsed: 0:00:07.121282\n",
      "\n",
      "begin StandardScaler LogisticRegression ..., shape:  (65144, 91)\n",
      "0.0001  ->  0.7046061904318877 , time elapsed: 0:00:02.015648\n",
      "0.001  ->  0.7157336419208571 , time elapsed: 0:00:03.528196\n",
      "0.01  ->  0.7165269494905575 , time elapsed: 0:00:05.393060\n",
      "0.1  ->  0.7163210127466281 , time elapsed: 0:00:06.265724\n",
      "1  ->  0.716286536215492 , time elapsed: 0:00:06.414533\n",
      "10.0  ->  0.7162827836867512 , time elapsed: 0:00:06.325494\n",
      "100.0  ->  0.7162823746690279 , time elapsed: 0:00:06.938230\n",
      "1000.0  ->  0.7162824524524554 , time elapsed: 0:00:06.840324\n",
      "10000.0  ->  0.7162824718808714 , time elapsed: 0:00:06.888091\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================================\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) \n",
    "# с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. \n",
    "\n",
    "\n",
    "L2_LR = [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "X_test_trans = scaler.transform(X_test)\n",
    "\n",
    "print ''\n",
    "print 'begin StandardScaler LogisticRegression ..., shape: ', X_train.shape\n",
    "\n",
    "# roc_auc_scorer \n",
    "for n in L2_LR:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty='l2',C=n, random_state=241)\n",
    "    clf.fit(X_train_trans, y_train)\n",
    "    \n",
    "    scores = cross_val_score(clf, X_test_trans, y_test, scoring='roc_auc', cv=cv)\n",
    "    print n, ' -> ', scores.mean(),  ', time elapsed:', datetime.datetime.now() - start_time\n",
    "\n",
    "# Вывод    \n",
    "# 0.0001  ->  0.7044488575866314 , time elapsed: 0:00:02.233493\n",
    "# 0.001  ->  0.7153558580738213 , time elapsed: 0:00:03.603334\n",
    "# 0.01  ->  0.716121852574402 , time elapsed: 0:00:05.956439\n",
    "# 0.1  ->  0.7159255905069706 , time elapsed: 0:00:07.078326\n",
    "# 1  ->  0.7158944792086537 , time elapsed: 0:00:06.951650\n",
    "# 10.0  ->  0.7158899279505536 , time elapsed: 0:00:07.043253\n",
    "# 100.0  ->  0.7158893832069998 , time elapsed: 0:00:06.967917\n",
    "# 1000.0  ->  0.7158893637590881 , time elapsed: 0:00:07.009808\n",
    "# 10000.0  ->  0.7158893248443823 , time elapsed: 0:00:06.991341\n",
    "#   \n",
    "\n",
    "# Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? \n",
    "## Лучшее качество достигнуто при значении L2 = 0.01, качество 0.716121852574402\n",
    "# Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? \n",
    "## Логистическая регрессия показывает несколько лучшее качество (~ 5%)\n",
    "# Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "## Логистическая регрессия работает значительно выбстрее градиентного бустинга\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "\n",
    "# 2. Среди признаков в выборке есть категориальные, которые мы использовали как числовые,\n",
    "# что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: \n",
    "# lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. \n",
    "# Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке \n",
    "# с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?\n",
    "\n",
    "X_new = X.copy()\n",
    "drop_cols = ['lobby_type', 'r1_hero', 'r2_hero', \n",
    "            'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', \n",
    "            'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "X_new = X_new.drop(drop_cols, axis=1)\n",
    "\n",
    "# NEW SPLIT\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, Y, test_size=0.33, random_state=241)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_new)\n",
    "X_train_trans_new = scaler.transform(X_train_new)\n",
    "X_test_trans_new = scaler.transform(X_test_new)\n",
    "\n",
    "print ''\n",
    "print 'begin StandardScaler LogisticRegression ..., shape: ', X_train_new.shape\n",
    "\n",
    "for n in L2_LR:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty='l2',C=n, random_state=241)\n",
    "    clf.fit(X_train_trans_new, y_train)\n",
    "    \n",
    "    scores = cross_val_score(clf, X_test_trans_new, y_test, scoring='roc_auc', cv=cv)\n",
    "    print n, ' -> ', scores.mean(),  ', time elapsed:', datetime.datetime.now() - start_time\n",
    "\n",
    "# Вывод\n",
    "# 0.0001  ->  0.7046061904318877 , time elapsed: 0:00:01.987312\n",
    "# 0.001  ->  0.7157336419208571 , time elapsed: 0:00:03.494213\n",
    "# 0.01  ->  0.7165269494905575 , time elapsed: 0:00:05.229055\n",
    "# 0.1  ->  0.7163210127466281 , time elapsed: 0:00:05.581821\n",
    "# 1  ->  0.716286536215492 , time elapsed: 0:00:06.137357\n",
    "# 10.0  ->  0.7162827836867512 , time elapsed: 0:00:06.219873\n",
    "# 100.0  ->  0.7162823746690279 , time elapsed: 0:00:06.148362\n",
    "# 1000.0  ->  0.7162824524524554 , time elapsed: 0:00:06.163399\n",
    "# 10000.0  ->  0.7162824718808714 , time elapsed: 0:00:06.143865\n",
    "## После применения  кол-ва параметров качество сильно не изменилось, по прежнему лучший результат \n",
    "## 0.01  ->  0.7165269494905575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Всего различных идентификаторов героев::  112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin StandardScaler+X_pick LogisticRegression ..., shape:  (65144, 203)\n",
      "0.0001  ->  0.7295677341810286 , time elapsed: 0:00:04.125688\n",
      "0.001  ->  0.7483507367761324 , time elapsed: 0:00:07.448855\n",
      "0.01  ->  0.7501496053631792 , time elapsed: 0:00:11.387636\n",
      "0.1  ->  0.7499499183329983 , time elapsed: 0:00:13.275921\n",
      "1  ->  0.7499034235962837 , time elapsed: 0:00:13.960815\n",
      "10.0  ->  0.749897531535672 , time elapsed: 0:00:13.808441\n",
      "100.0  ->  0.7498963256079507 , time elapsed: 0:00:13.812769\n",
      "1000.0  ->  0.7498961894405547 , time elapsed: 0:00:13.930174\n",
      "10000.0  ->  0.7498962477836765 , time elapsed: 0:00:13.669345\n",
      "\n",
      "Test - features_test\n",
      "clf.predict_proba(features_test_trans):  [[0.47653616 0.52346384]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:98: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================================\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 3. На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, \n",
    "# какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, \n",
    "# и некоторые из них выигрывают чаще, чем другие. \n",
    "# Выясните из данных, сколько различных идентификаторов героев существует в \n",
    "# данной игре (вам может пригодиться фукнция unique или value_counts).\n",
    "summare = [] \n",
    "for dc in drop_cols[1:]:\n",
    "    summare += list(X[dc].unique())\n",
    "    \n",
    "N_hero_type =      max(set(summare))  # len(set(summare) )\n",
    "\n",
    "print ''\n",
    "print 'Всего различных идентификаторов героев:: ', N_hero_type\n",
    "# Всего различных идентификаторов героев::  112\n",
    " \n",
    "# 4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. \n",
    "# Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, \n",
    "# если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; \n",
    "# минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной \n",
    "# преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.\n",
    "\n",
    "# N — количество различных героев в выборке\n",
    "X_pick = np.zeros((X.shape[0], N_hero_type)) \n",
    "\n",
    "for i, match_id in enumerate(X.index):\n",
    "    for p in xrange(5):        \n",
    "        X_pick[i, X.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, X.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "\n",
    "# 5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. \n",
    "# Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?\n",
    "\n",
    "# NEW SPLIT\n",
    "for n in  range(N_hero_type):\n",
    "    key = 'hero_type_%d' % n \n",
    "    X[key] = pandas.Series(X_pick[:, n], index=X.index) \n",
    "        \n",
    "# Удалим категориальные признаки\n",
    "X = X.drop(drop_cols, axis=1)        \n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=241)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "X_test_trans = scaler.transform(X_test)\n",
    "\n",
    "bestModel = [None, -1]\n",
    "print ''\n",
    "print 'begin StandardScaler+X_pick LogisticRegression ..., shape: ', X_train.shape\n",
    "for n in L2_LR:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(C=n, random_state=241)\n",
    "    clf.fit(X_train_trans, y_train)\n",
    "    \n",
    "    scores = cross_val_score(clf, X_test_trans, y_test, scoring='roc_auc', cv=cv)\n",
    "    print n, ' -> ', scores.mean(),  ', time elapsed:', datetime.datetime.now() - start_time\n",
    "    \n",
    "    if(bestModel[1] == -1 or bestModel[1] < scores.mean()):\n",
    "        bestModel[0] = clf\n",
    "        bestModel[1] = scores.mean()\n",
    "    \n",
    "    \n",
    "# Вывод    \n",
    "# begin StandardScaler+X_pick LogisticRegression ..., shape:  (65144, 203)\n",
    "# 0.0001  ->  0.7295677341810286 , time elapsed: 0:00:04.960630\n",
    "# 0.001  ->  0.7483507367761324 , time elapsed: 0:00:08.500225\n",
    "# 0.01  ->  0.7501496053631792 , time elapsed: 0:00:11.987407\n",
    "# 0.1  ->  0.7499499183329983 , time elapsed: 0:00:13.283278\n",
    "# 1  ->  0.7499034235962837 , time elapsed: 0:00:13.264894\n",
    "# 10.0  ->  0.749897531535672 , time elapsed: 0:00:13.481384\n",
    "# 100.0  ->  0.7498963256079507 , time elapsed: 0:00:13.736012\n",
    "# 1000.0  ->  0.7498961894405547 , time elapsed: 0:00:13.610593\n",
    "# 10000.0  ->  0.7498962477836765 , time elapsed: 0:00:13.672530\n",
    "## Лучшее качество  0.01  ->  0.7501496053631792\n",
    "## Преобразование порядковых принзаков в категориальные позволило значительно улучшить модель.\n",
    "\n",
    "\n",
    "# 6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из \n",
    "# изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные \n",
    "# вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой \n",
    "# (т.е. что модель не получилась константной).   \n",
    " \n",
    "print ''    \n",
    "print 'Test - features_test' \n",
    "\n",
    "features_test = features_test.fillna(0)\n",
    "\n",
    "X_pick = np.zeros((features_test.shape[0], N_hero_type)) \n",
    "\n",
    "for i, match_id in enumerate(features_test.index):\n",
    "    for p in xrange(5):        \n",
    "        X_pick[i, features_test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, features_test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "        \n",
    "for n in  range(N_hero_type):\n",
    "    key = 'hero_type_%d' % n \n",
    "    features_test[key] = pandas.Series(X_pick[:, n], index=features_test.index)   \n",
    "\n",
    "# Удалим категориальные признаки\n",
    "features_test = features_test.drop(drop_cols, axis=1)     \n",
    "     \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_test)         \n",
    "features_test_trans = scaler.transform(features_test)  \n",
    "print 'clf.predict_proba(features_test_trans): ', bestModel[0].predict_proba(features_test_trans)\n",
    " \n",
    "\n",
    "# Распределение побед:  0.47628219 0.52371781   \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
